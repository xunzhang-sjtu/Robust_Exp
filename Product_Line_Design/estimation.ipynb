{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb07b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimate_parameters (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using Optim\n",
    "using Random\n",
    "using StatsFuns\n",
    "using JuMP\n",
    "using MosekTools\n",
    "using StatsBase\n",
    "using SparseArrays # 可选，用于处理稀疏性（如果数据量很大）\n",
    "using FileIO\n",
    "using JLD2\n",
    "using Plots\n",
    "using LaTeXStrings\n",
    "\n",
    "using DataFrames, Colors\n",
    "using StatsPlots   # 提供 boxplot，基于 Plots\n",
    "\n",
    "include(\"Data_Generation_PLD.jl\")\n",
    "include(\"Estimation_PLD.jl\")\n",
    "# include(\"Models_PLD.jl\")\n",
    "# include(\"Evaluation_PLD.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c69fc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 2 # num of product\n",
    "N_x = 20 # num of product feature\n",
    "c_l = ones(N_x)  # X * c_l >= d_r\n",
    "d_r = ones(N) * 5\n",
    "rev_gap = 0.001\n",
    "N_u = 1 # num of customer feature\n",
    "S_train = 200 # num of training samples\n",
    "S_test = 1 # num of training samples\n",
    "m = 5 # num of candidates in training samples\n",
    "N_nonzero = 5 # num of nonzero entries in A\n",
    "lambda_list = [0.01]\n",
    "gamma_list = [0.0,0.01,0.05,0.1,0.15,0.2,0.3,0.4,0.5]\n",
    "gamma_list = [0.0]\n",
    "\n",
    "instances = 10\n",
    "Random.seed!(2)\n",
    "project_dir = \"N=$(N)_N_x=$(N_x)_N_u=$(N_u)_S_train=$(S_train)_N_nonzero=$(N_nonzero)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cd637ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/\n"
     ]
    }
   ],
   "source": [
    "current_dir = pwd()\n",
    "parent_dir = dirname(current_dir)\n",
    "grand_pa_dir = dirname(parent_dir)\n",
    "data_dir = string(dirname(grand_pa_dir), \"/Data/Product_Line_Design/\")\n",
    "if !isdir(data_dir)\n",
    "    mkpath(data_dir)\n",
    "end\n",
    "data_dir = string(data_dir,project_dir)\n",
    "println(\"Data directory: \", data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d6a50",
   "metadata": {},
   "source": [
    "#### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f29673d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_w (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function compute_w(alpha0,alpha,beta,A,z_input)\n",
    "    nu0 = alpha0 + beta' * z_input;\n",
    "    nu = alpha .+ A * z_input;\n",
    "    return nu0,nu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c01ffde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=1/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=2/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=3/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=4/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=5/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=6/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=7/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=8/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=9/\n",
      "/Users/zhangxun/Dropbox/Research/Robust_Exp/Data/Product_Line_Design/N=2_N_x=20_N_u=1_S_train=200_N_nonzero=5/instance=10/\n"
     ]
    }
   ],
   "source": [
    "Input_Data = Dict()\n",
    "ins = 1\n",
    "while ins <= instances\n",
    "    data_dir_ins = string(data_dir, \"instance=$ins/\")\n",
    "    # ****** Data ******\n",
    "    theta_true, r_params = Generate_Wang_Qi_Max_True_Paras(N_x,N_u,N_nonzero);\n",
    "    X_train,Y_train,Z_train = Generate_Wang_Qi_Max_True_Data(N_x, N_u, S_train, m,theta_true);\n",
    "    X_test,Y_test,Z_test = Generate_Wang_Qi_Max_True_Data(N_x, N_u, S_test, m,theta_true);\n",
    "\n",
    "    Input_Data[\"theta_true_ins=$ins\"] = theta_true\n",
    "    Input_Data[\"r_params_ins=$ins\"] = r_params\n",
    "    Input_Data[\"X_train_ins=$ins\"] = X_train\n",
    "    Input_Data[\"Y_train_ins=$ins\"] = Y_train\n",
    "    Input_Data[\"Z_train_ins=$ins\"] = Z_train\n",
    "    Input_Data[\"X_test_ins=$ins\"] = X_test\n",
    "    Input_Data[\"Y_test_ins=$ins\"] = Y_test\n",
    "    Input_Data[\"Z_test_ins=$ins\"] = Z_test\n",
    "    \n",
    "    ins = ins + 1\n",
    "    println(data_dir_ins)\n",
    "end\n",
    "save(string(data_dir,\"Input_Data.jld2\"),Input_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "610ede21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimate_parameters_fast (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. 预计算所有扩展设计矩阵\n",
    "# ------------------------------------------------------------\n",
    "function precompute_extended_designs(X::Vector{Matrix{Float64}}, Z::Matrix{Float64})\n",
    "    n = length(X)\n",
    "    d = size(X[1], 2)\n",
    "    p = size(Z, 2)\n",
    "    total_dim = (d + 1) * (p + 1)\n",
    "    X_tilde = Vector{Matrix{Float64}}(undef, n)\n",
    "\n",
    "    # 预分配临时向量以避免重复分配\n",
    "    x_tilde_temp = Vector{Float64}(undef, total_dim)\n",
    "\n",
    "    for i in 1:n\n",
    "        mi = size(X[i], 1)\n",
    "        Xt = Matrix{Float64}(undef, mi, total_dim)\n",
    "\n",
    "        @inbounds for j in 1:mi\n",
    "            x_ij = @view X[i][j, :]\n",
    "            z_i = @view Z[i, :]\n",
    "\n",
    "            idx = 1\n",
    "            x_tilde_temp[idx] = 1.0\n",
    "            idx += 1\n",
    "\n",
    "            @views x_tilde_temp[idx:idx+d-1] .= x_ij\n",
    "            idx += d\n",
    "\n",
    "            @inbounds for k in 1:p\n",
    "                zk = z_i[k]\n",
    "                x_tilde_temp[idx] = zk\n",
    "                idx += 1\n",
    "                @views x_tilde_temp[idx:idx+d-1] .= zk .* x_ij\n",
    "                idx += d\n",
    "            end\n",
    "\n",
    "            @views Xt[j, :] .= x_tilde_temp\n",
    "        end\n",
    "        X_tilde[i] = Xt\n",
    "    end\n",
    "    return X_tilde\n",
    "end\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. 快速单样本负对数似然（使用预计算的 Xt_i）\n",
    "# ------------------------------------------------------------\n",
    "function neg_log_likelihood_single_fast(theta::AbstractVector, Xt_i::AbstractMatrix, y_i::Int)\n",
    "    mi = size(Xt_i, 1)\n",
    "    # 计算所有产品的效用：<θ, x̃_ij> for j=1..mi\n",
    "    utilities = Xt_i * theta          # mi 维向量\n",
    "    # 添加默认选项（效用为 0）\n",
    "    m_val = maximum(utilities)\n",
    "    # 数值稳定的 log-sum-exp: log(sum(exp(u))) = m + log(sum(exp(u - m)))\n",
    "    shifted_utils = utilities .- m_val\n",
    "    sum_exp = sum(exp, shifted_utils) + exp(-m_val)  # + exp(0 - m_val) for default option\n",
    "    log_denominator = m_val + log(sum_exp)\n",
    "\n",
    "    if y_i == 0\n",
    "        log_prob = -log_denominator  # 因为 U0 = 0 → log(exp(0)/denom) = -log_denom\n",
    "    else\n",
    "        log_prob = utilities[y_i] - log_denominator\n",
    "    end\n",
    "\n",
    "    return -log_prob\n",
    "end\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. 快速整体负对数似然\n",
    "# ------------------------------------------------------------\n",
    "function neg_log_likelihood_fast(theta::AbstractVector, X_tilde::Vector{Matrix{Float64}}, Y::Vector{Int})\n",
    "    n = length(Y)\n",
    "    total_neg_ll = 0.0\n",
    "    @inbounds for i in 1:n\n",
    "        total_neg_ll += neg_log_likelihood_single_fast(theta, X_tilde[i], Y[i])\n",
    "    end\n",
    "    return total_neg_ll / n\n",
    "end\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Lasso 目标函数（使用预计算数据）\n",
    "# ------------------------------------------------------------\n",
    "function lasso_objective_fast(theta::AbstractVector, lambda::Float64, X_tilde::Vector{Matrix{Float64}}, Y::Vector{Int})\n",
    "    nll = neg_log_likelihood_fast(theta, X_tilde, Y)\n",
    "    l1_penalty = lambda * norm(theta, 1)\n",
    "    return nll + l1_penalty\n",
    "end\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. 参数解析（不变）\n",
    "# ------------------------------------------------------------\n",
    "function parameter_divide(theta_hat, d::Int, p::Int)\n",
    "    alpha0_hat = 0.0\n",
    "    alpha_hat = zeros(d)\n",
    "    beta_hat = zeros(p)\n",
    "    A_hat = zeros(d, p)\n",
    "\n",
    "    idx = 1\n",
    "    alpha0_hat = theta_hat[idx]\n",
    "    idx += 1\n",
    "\n",
    "    alpha_hat = theta_hat[idx:idx+d-1]\n",
    "    idx += d\n",
    "\n",
    "    for k in 1:p\n",
    "        beta_hat[k] = theta_hat[idx]\n",
    "        idx += 1\n",
    "        A_hat[:, k] = theta_hat[idx:idx+d-1]\n",
    "        idx += d\n",
    "    end\n",
    "    return alpha0_hat, alpha_hat, beta_hat, A_hat\n",
    "end\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. 主估计函数（优化版）\n",
    "# ------------------------------------------------------------\n",
    "function estimate_parameters_fast(\n",
    "    X::Vector{Matrix{Float64}},\n",
    "    Y::Vector{Int64},\n",
    "    Z::Matrix{Float64},\n",
    "    lambda::Float64,\n",
    "    d::Int,\n",
    "    p::Int;\n",
    "    initial_theta = nothing,\n",
    "    precomputed_X_tilde = nothing\n",
    ")\n",
    "    # 预计算扩展设计（如果未提供）\n",
    "    if isnothing(precomputed_X_tilde)\n",
    "        @time X_tilde = precompute_extended_designs(X, Z)\n",
    "    else\n",
    "        X_tilde = precomputed_X_tilde\n",
    "    end\n",
    "\n",
    "    total_dim = (d + 1) * (p + 1)\n",
    "    if isnothing(initial_theta)\n",
    "        initial_theta = randn(total_dim) * 0.1\n",
    "    end\n",
    "\n",
    "    # 目标函数闭包\n",
    "    obj(theta) = lasso_objective_fast(theta, lambda, X_tilde, Y)\n",
    "\n",
    "    # 使用 OWLQN 优化（专为 L1 设计）\n",
    "    # result = optimize(\n",
    "    #     obj,\n",
    "    #     initial_theta,\n",
    "    #     OWLQN(lambda),\n",
    "    #     Optim.Options(show_trace = false, g_tol = 1e-6, iterations = 1000, time_limit = 300)\n",
    "    # )\n",
    "    result = optimize(obj, initial_theta, LBFGS(), Optim.Options(show_trace=false, g_tol=1e-6, iterations=1000,time_limit = 300))\n",
    "\n",
    "    theta_hat = Optim.minimizer(result)\n",
    "    alpha0_hat, alpha_hat, beta_hat, A_hat = parameter_divide(theta_hat, d, p)\n",
    "\n",
    "    return alpha0_hat, alpha_hat, beta_hat, A_hat, result, X_tilde\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f45a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_w (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function compute_w(alpha0,alpha,beta,A,z_input)\n",
    "    nu0 = alpha0 + beta' * z_input;\n",
    "    nu = alpha .+ A * z_input;\n",
    "    return nu0,nu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb07b9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambda_list = [0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43072df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_true = [1.2489, 0.4442, -0.295, -0.3563, -1.3427, 0.7667, 0.0998, 0.7176, -0.2489, -0.4407, -0.7148, 0.094, 0.4154, 1.1798, -1.7647, 0.9052, 0.0207, 0.7518, 0.161, 0.1593, -0.6618]\n",
      "  0.000122 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [1.3377, 0.838, -0.3362, -0.765, -0.9344, 0.5413, -0.0662, 0.6018, -0.0311, -0.694, -0.7322, 0.3736, 0.0932, 0.8604, -1.6579, 0.028, -0.0778, 0.7486, 0.1068, 0.1427, -0.2321]\n",
      "*** norm = 1.4016363932812217*****\n",
      "------------\n",
      "w_true = [0.7601, -0.9555, 0.5936, 0.0002, -0.3098, -0.9214, 0.2334, -0.8233, -0.4618, -0.4877, -1.3791, -0.9112, 0.2202, 0.1884, -0.9203, 2.201, 0.0117, -0.4393, -0.2038, 0.215, -0.2797]\n",
      "  0.000199 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [2.1202, -1.4785, 0.3432, 0.0091, -0.181, -1.4591, 0.4873, -1.2157, -0.3854, -1.1873, -1.7161, -1.1473, 0.5062, 0.2277, -1.3423, 2.3558, 0.1045, -0.2182, -0.4529, 0.1495, -0.5001]\n",
      "*** norm = 1.95775283909609*****\n",
      "------------\n",
      "w_true = [2.5547, -0.2549, 0.6046, 0.4216, -1.4614, 1.3551, 0.1317, 0.4202, -0.4065, -0.4115, 0.344, -1.9604, -0.0999, -0.1114, 0.5389, -0.0105, 0.6174, 0.5997, 0.22, -0.2831, -0.6218]\n",
      "  0.000072 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [1.3087, -0.3053, 0.0609, 0.3177, -1.4054, 1.308, 0.6354, 0.6426, -0.3168, -0.1588, 0.1112, -1.6821, 0.0456, -0.3951, 0.8897, -0.103, 0.1569, 0.4828, 0.3806, 0.0881, -0.8214]\n",
      "*** norm = 1.7423970519723622*****\n",
      "------------\n",
      "w_true = [2.1439, -0.5723, 0.7254, -1.9357, -2.2103, -0.9418, -0.2732, 2.3766, 1.576, 0.2302, -0.1715, 0.3868, 0.0445, -0.0218, 0.3194, 0.3268, -0.4517, -0.8014, -0.1282, -0.8662, -0.7335]\n",
      "  0.000088 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [2.1479, -1.1129, 0.3521, -1.2064, -1.7684, -1.0576, -0.2583, 2.5502, 1.204, 0.0291, -0.0344, 0.2643, -0.7556, -0.0195, -0.1353, 0.9661, -0.6624, -0.6523, -0.0869, -0.367, -0.0515]\n",
      "*** norm = 1.8583469480569228*****\n",
      "------------\n",
      "w_true = [1.2107, 0.8034, -0.9141, -0.5607, 1.483, 0.8059, -0.8498, -0.0709, -0.8978, -0.8695, 1.0075, -0.5504, 0.9994, 0.8073, 0.2355, 0.4388, 0.3329, -0.244, -0.7965, 0.3456, 0.8157]\n",
      "  0.000071 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [0.482, 0.6291, -1.0148, -0.5595, 1.9899, 0.8459, -1.4296, -0.2064, -0.9043, -0.9584, 1.394, -0.7784, 1.3438, 0.7726, 0.6662, 0.2286, 0.7167, -0.6499, -0.9636, 0.6112, 1.0411]\n",
      "*** norm = 1.4848511753217124*****\n",
      "------------\n",
      "w_true = [0.6894, 0.1479, 0.1118, 0.2426, -0.9787, 0.4155, 0.2441, 0.2767, -0.621, -0.2035, 0.4709, 0.6096, -0.063, -0.2029, -0.2447, 0.4272, -0.1866, 0.9616, 2.0151, -0.4077, -0.2514]\n",
      "  0.000068 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [0.6175, 0.117, 0.1734, 0.0128, -1.2129, 1.1748, 0.2354, 0.2901, -1.1175, -0.3231, -0.0891, 0.4576, -0.182, -0.3823, -0.2141, 0.4948, -0.1385, 0.7857, 2.55, -0.5727, -0.1242]\n",
      "*** norm = 1.3063353836559846*****\n",
      "------------\n",
      "w_true = [0.9944, 0.9908, 1.4147, -1.4343, 0.0254, 0.4562, -1.6058, -0.5596, 0.5401, 0.5215, -0.5698, -0.0891, 0.4949, 0.4209, -0.338, -0.6568, 0.4714, 0.6906, 0.6456, 0.1404, -0.4379]\n",
      "  0.000078 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [2.7633, 1.3656, 0.8873, -1.6033, 0.9803, 0.5699, -1.8356, -0.7393, 0.5821, 1.0524, -0.9127, -0.0252, 0.0762, 0.6859, -0.2139, -0.5298, 0.4187, 1.1049, 0.7587, 0.0716, -0.4071]\n",
      "*** norm = 2.3369484555075837*****\n",
      "------------\n",
      "w_true = [0.7204, 0.5343, -0.082, 1.0611, 1.0439, 0.3347, -0.6211, -0.4389, -0.6337, 0.6775, 0.7493, 0.9362, -0.9222, -0.5602, 0.7503, -0.2726, -0.1109, -0.7443, 1.9231, 0.3296, -0.8738]\n",
      "  0.000074 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [1.1243, 0.4458, 0.2469, 1.1934, 1.1619, -0.1451, -0.1226, -0.8182, -0.5345, 1.1984, 1.4811, 0.4505, -1.0995, -0.5059, 0.9131, 0.546, -0.4734, -0.6638, 1.6525, 0.5732, -1.0798]\n",
      "*** norm = 1.740610651052584*****\n",
      "------------\n",
      "w_true = [2.2591, 0.1769, -0.8359, -0.0161, 0.4475, 0.5529, -0.8428, 0.8992, 0.361, -1.6317, -0.2412, 0.0106, -0.0726, 0.3647, 0.8802, -0.3146, 0.8897, -0.7401, -0.4948, 0.1542, -0.4178]\n",
      "  0.000142 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [1.3773, 0.1586, 0.0577, 0.484, 0.6337, 0.5002, -0.8011, 0.2085, 0.8275, -2.0938, 0.0883, -0.4528, -0.1963, 0.7662, 0.915, -0.6865, 1.0769, -1.0719, -0.5381, 0.4915, -0.7177]\n",
      "*** norm = 1.940094497333178*****\n",
      "------------\n",
      "w_true = [1.8867, -0.6445, 0.2176, 0.8457, -0.2892, 0.2858, -0.697, 0.1676, 0.3257, -0.0618, -0.3423, -0.2332, 0.5052, 0.6385, -0.8892, 0.5925, 0.3394, 0.0665, -0.1747, 0.5172, 0.2249]\n",
      "  0.000075 seconds (202 allocations: 355.281 KiB)\n",
      "w_ = [1.6731, -0.5538, 0.1185, 0.7826, -0.3343, 0.5808, -0.9422, 0.1806, 0.4285, 0.025, -0.2197, -0.0935, 0.3538, 0.7899, -0.7422, 0.511, 0.4296, -0.0019, -0.0146, 0.6151, 0.1052]\n",
      "*** norm = 0.6372884593789928*****\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for ins in 1:instances\n",
    "    theta_true = Input_Data[\"theta_true_ins=$ins\"]\n",
    "    r_params = Input_Data[\"r_params_ins=$ins\"]\n",
    "    X_train = Input_Data[\"X_train_ins=$ins\"]\n",
    "    Y_train = Input_Data[\"Y_train_ins=$ins\"]\n",
    "    Z_train = Input_Data[\"Z_train_ins=$ins\"]\n",
    "    X_test = Input_Data[\"X_test_ins=$ins\"]\n",
    "    Y_test = Input_Data[\"Y_test_ins=$ins\"]\n",
    "    Z_test = Input_Data[\"Z_test_ins=$ins\"]\n",
    "\n",
    "    z_input = Z_test[1,:];\n",
    "    nu0_true,nu_true = compute_w(theta_true.alpha0,theta_true.alpha,theta_true.beta,theta_true.A,z_input);\n",
    "    w_true = [nu0_true;nu_true];\n",
    "    println(\"w_true = \",round.(w_true,digits=4))\n",
    "    for lambda in lambda_list\n",
    "        alpha0, alpha, beta, A, result, X_tilde = estimate_parameters_fast(X_train, Y_train, Z_train, lambda, N_x, N_u);\n",
    "        nu0_,nu_ = compute_w(alpha0,alpha,beta,A,z_input);\n",
    "        w_ = [nu0_;nu_];\n",
    "        println(\"w_ = \",round.(w_,digits=4))\n",
    "        println(\"*** norm = \",norm(w_ .- w_true,2),\"*****\")\n",
    "    end\n",
    "    println(\"------------\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
